{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "from itables import init_notebook_mode\n",
    "import os\n",
    "import seaborn as sns\n",
    "import time\n",
    "import json\n",
    "import ast\n",
    "import dask.dataframe as dd\n",
    "from collections import Counter\n",
    "\n",
    "init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_json_to_csv_by_folder():\n",
    "    base_dir = os.path.join(os.path.dirname(os.getcwd()), 'archive_data')\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for subdir, _, files in os.walk(base_dir):\n",
    "        df_list = []\n",
    "\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_json(file_path)\n",
    "                    df_list.append(df)\n",
    "                except ValueError as ve:\n",
    "                    print(f\"Błąd podczas przetwarzania pliku {file_path}: {ve}\")\n",
    "\n",
    "        if df_list:\n",
    "            combined_df = pd.concat(df_list, ignore_index=True)\n",
    "            folder_name = os.path.basename(subdir)\n",
    "            csv_file_name = folder_name + '.csv'\n",
    "            csv_file_path = os.path.join(base_dir, csv_file_name)\n",
    "            combined_df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Zapisano plik CSV.\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Czas przetwarzania: {end_time - start_time} sekund\")\n",
    "\n",
    "# Uruchom przetwarzanie danych z JSON do CSV\n",
    "process_json_to_csv_by_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funkcja wczytywania danych do df\n",
    "def combine_csv_to_df():\n",
    "    base_dir = os.path.join(os.path.dirname(os.getcwd()), 'archive_data')\n",
    "    combined_df_list = []\n",
    "\n",
    "    for file in os.listdir(base_dir):\n",
    "        if file.endswith('.csv'):\n",
    "            csv_file_path = os.path.join(base_dir, file)\n",
    "            print(f\"Wczytywanie pliku CSV.\")\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file_path)\n",
    "                combined_df_list.append(df)\n",
    "            except pd.errors.EmptyDataError as e:\n",
    "                print(f\"Błąd podczas wczytywania pliku CSV {csv_file_path}: {e}\")\n",
    "\n",
    "    if not combined_df_list:\n",
    "        print(\"Żadne pliki CSV nie zostały wczytane.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    combined_df = pd.concat(combined_df_list, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Uruchom łączenie plików CSV w jeden DataFrame\n",
    "df = combine_csv_to_df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 1. Ogólny przegląd danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Początkowy przegląd losowych 5 wierszy\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie unikalnych wartości w kolumnach\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mark1= f\"\"\"\n",
    "## Obserwacje wstępne:\n",
    "### 1. Dane archiwalne ofert pracy ze strony JustJoinIT.\n",
    "### 2. Dane zawierają **{len(df)}** wierszy oraz **{len(df.columns)}** kolumn.\n",
    "\"\"\"\n",
    "display(Markdown(mark1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuniecie nie optrzebnych kolumn\n",
    "df = df[['title', 'street', 'city', 'country_code', \n",
    "       #'address_text',\n",
    "       'marker_icon', 'workplace_type', 'company_name', \n",
    "       #'company_url', 'company_size', \n",
    "       'experience_level', \n",
    "       #'latitude', 'longitude',\n",
    "       'published_at', 'remote_interview', 'id', 'employment_types',\n",
    "       #'company_logo_url', \n",
    "       'skills', 'remote', 'open_to_hire_ukrainians',\n",
    "       #'display_offer', \n",
    "       #'multilocation', 'way_of_apply'\n",
    "       ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['published_at'] = pd.to_datetime(df['published_at'], format='ISO8601', utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.duplicated(subset=['title'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('title == \"Analityk Systemowy (Integracje Systemów)\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df.duplicated(subset=['title', 'street', 'city', 'company_name', 'published_at'])].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przeprowadzone operacje wstępne:\n",
    "#### 1. Sprawdzenie jakie dane zawiera DataFrame oraz usunięcie zbędnych kolumn.\n",
    "#### 2. Naprawienie kolumny z czasem publikacji.\n",
    "#### 3. Wykrycie dużej ilości duplikatów, usunięcie powtarzających się ofert pracy w danych.\n",
    "\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Przegląd pojedyńczysz kolumn\n",
    "<br><br>\n",
    "\n",
    "### 1. Stanowiska pracy i TOP15 poszukiwanych pracowników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie ilości unikatowych stanowisk pracy\n",
    "df['title'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie powtarzania się stanowisk pracy\n",
    "df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = df['title'].value_counts() \\\n",
    "    .head(15) \\\n",
    "    .plot(kind='bar', title='Top 15 ofert pracy')\n",
    "ax.set_xlabel('Popularne zawody')\n",
    "ax.set_ylabel('Ilości')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_15_titles = df['title'].value_counts().head(15)\n",
    "top_15_text = '\\n'.join([f\"- {title}: {count}\" for title, count in top_15_titles.items()])\n",
    "\n",
    "mark2= f\"\"\"\n",
    "### Obserwacje:\n",
    "#### 1. Dane zawierają: **{df['title'].nunique()}** stanowisk pracy z: **{df['company_name'].nunique()}** firm.\n",
    "#### 2. Pierwsza piętnastka najczęściej wystepujących ofert:\\n{top_15_text}.\n",
    "\"\"\"\n",
    "display(Markdown(mark2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Typy pracy, poziom doświadczenia oraz rekrutacja zdalna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie ilości unikatowych typów pracy\n",
    "df['workplace_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie ilości unikalnych poziomów doświadczenia\n",
    "df['experience_level'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie liczba ofert pracy z możliwościa rekrutacji zdalnej\n",
    "df['remote'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "worktyp = df['workplace_type'].value_counts()\n",
    "total_worktyp = worktyp.sum() \n",
    "worktyp_counts = '\\n'.join([f\"- {worktyp}: {count} ({(count / total_worktyp * 100):.2f}%)\" for worktyp, count in worktyp.items()])\n",
    "\n",
    "expeLvl = df['experience_level'].value_counts()\n",
    "total_expeLvl = expeLvl.sum()\n",
    "expeLvl_counts = '\\n'.join([f\"- {expeLvl}: {count} ({(count / total_expeLvl * 100):.2f}%)\" for expeLvl, count in expeLvl.items()])\n",
    "\n",
    "remoteInt = df['remote'].value_counts()\n",
    "total_remoteInt = expeLvl.sum()\n",
    "remoteInt_counts = '\\n'.join([f\"- {remoteInt}: {count} ({(count / total_remoteInt * 100):.2f}%)\" for remoteInt, count in remoteInt.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wykresy \n",
    "worktyp_labels = worktyp.index\n",
    "worktyp_sizes = worktyp.values\n",
    "\n",
    "expeLvl_labels = expeLvl.index\n",
    "expeLvl_sizes = expeLvl.values\n",
    "\n",
    "remoteInt_labels = remoteInt.index\n",
    "remoteInt_sizes =  remoteInt.values\n",
    "\n",
    "# Tworzenie wykresów kołowych\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Wykres dla workplaceType\n",
    "axes[0].pie(worktyp_sizes, labels=worktyp_labels, autopct='%1.1f%%', colors=plt.cm.Paired.colors)\n",
    "axes[0].set_title('Rodzaje pracy')\n",
    "\n",
    "# Wykres dla experienceLevel\n",
    "axes[1].pie(expeLvl_sizes, labels=expeLvl_labels, autopct='%1.1f%%', colors=plt.cm.Accent.colors)\n",
    "axes[1].set_title('Poziomy doświadczenia')\n",
    "\n",
    "# Wykres dla remoteInterview\n",
    "axes[2].pie(remoteInt_sizes, labels=remoteInt_labels, autopct='%1.1f%%', colors=plt.cm.Set1.colors)\n",
    "axes[2].set_title('Rekrutacja zdalna')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mark3= f\"\"\"\n",
    "### Wnioski:\n",
    "#### 1. Dane zawierają: **{df['workplace_type'].nunique()}** rodzaje pracy:\\n {worktyp_counts}.  \n",
    "#### 2. Liczba ofert pracy dla poszczególnych poziomów doświadczenia:\\n{expeLvl_counts}.\n",
    "#### 3. Liczba ofert pracy z możliwościa rekrutacji zdalnej:\\n{remoteInt_counts}.\n",
    "\"\"\"\n",
    "display(Markdown(mark3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sprawdzenie częstotliwości ofert pracy dla Ukraińców."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forUA = df['open_to_hire_ukrainians'].value_counts()\n",
    "total_forUA = forUA.sum() \n",
    "forUA_counts = '\\n'.join([f\"- {forUA}: {count} ({(count / total_forUA * 100):.2f}%)\" for forUA, count in forUA.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generowanie wykresu kołowego\n",
    "plt.pie(forUA, labels=forUA.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Dostępne oferty dla Ukraińców')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mark4= f\"\"\"\n",
    "### Obserwacje:\n",
    "#### Oferty dla Ukraińców: \\n {forUA_counts}. \n",
    "\"\"\"\n",
    "display(Markdown(mark4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### 4. Analiza ofert pracy w poszczególnych miastach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie ilości unikatowych miejsc zatrudnienia\n",
    "df['city'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ocena liczby unikatowych lokalizacji zatrudnienia\n",
    "unique_locations_initial = df['city'].nunique()\n",
    "\n",
    "city_mapping = {\n",
    "    'Poland (Remote)' : 'Polska',\n",
    "    'Poland' : 'Polska', \n",
    "    'Remote Poland' : 'Polska',\n",
    "    'Warsaw' : 'Warszawa',\n",
    "    'Warszawa (Centrum)' : 'Warszawa',\n",
    "    }\n",
    "\n",
    "# Normalizacja nazw miast\n",
    "df['city'] = df['city'].replace(city_mapping)\n",
    "\n",
    "# Wyliczenie procentowego udziału każdej lokalizacji\n",
    "location_share = df['city'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Przypisanie lokalizacji do kategorii \"Inne\", jeśli występują mniej niż w 3,5% przypadków\n",
    "total_small_share = location_share[location_share < 3.5].sum()\n",
    "\n",
    "# Redukcja do lokalizacji występujących co najmniej w 3,5% przypadków\n",
    "location_share = location_share[location_share >= 3.5]\n",
    "\n",
    "# Dodanie kategorii \"Inne\" do zsumowanych pomniejszych kategorii\n",
    "location_share['Inne'] = total_small_share\n",
    "\n",
    "# Tworzenie wizualizacji w formie wykresu pi\n",
    "plt.pie(location_share, labels=location_share.index, autopct='%1.1f%%', startangle=270)\n",
    "plt.title('Oferty zatrudnienia w poszczególnych miastach')\n",
    "plt.show()\n",
    "\n",
    "# Mapowanie lokalizacji na podstawie ich częstości występowania\n",
    "location_count = df['city'].value_counts()\n",
    "\n",
    "# Stworzenie indeksu bazującego na częstości wystąpień\n",
    "location_index_map = {loc: idx + 1 for idx, loc in enumerate(location_count.index)}\n",
    "\n",
    "# Aktualizacja kolumny 'city' przy użyciu indeksu bez wpływu na wykres\n",
    "df['city_index'] = df['city'].map(location_index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_citytyp = location_count.sum() \n",
    "# Wyliczanie procentowego udziału dla każdej lokalizacji\n",
    "location_percentage = (location_count / total_citytyp) * 100\n",
    "\n",
    "# Filtrowanie lokalizacji do wyświetlenia\n",
    "significant_locations = {location: count for location, count in location_count.items() if location_percentage[location] >= 2}\n",
    "\n",
    "significant_citytyp_counts = '\\n'.join([\n",
    "    f\"- {location}: {count} ({(count / total_citytyp * 100):.2f}%)\"\n",
    "    for location, count in significant_locations.items()\n",
    "])\n",
    "\n",
    "mark5 = f\"\"\"\n",
    "### Obserwacje:\n",
    "#### Prezentacja ilości ofert pracy w danych miejscowościach i ich procent w danych:\\n{significant_citytyp_counts}.\n",
    "#### W danych historycznych możemy zaobserwować że największe zapotrzebowanie na specjalistów w branży IT jest w miejscowościach:\n",
    "#### - Warszawa\n",
    "#### - Wrocław\n",
    "#### - Kraków\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(mark5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "### 5. Analiza czasu publikacji ogłoszeń."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konwersja kolumny 'publishedAt' na datę i czas\n",
    "df['published_at'] = pd.to_datetime(df['published_at'], errors='coerce')\n",
    "\n",
    "# Wyodrębnienie godziny z kolumny 'publishedAt'\n",
    "df['publication_hour'] = df['published_at'].dt.hour\n",
    "\n",
    "# Zliczanie liczby ogłoszeń na każdej godzinie\n",
    "hourly_counts = df['publication_hour'].value_counts().sort_index()\n",
    "\n",
    "# Tworzenie wykresu słupkowego\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(hourly_counts.index, hourly_counts.values, color='skyblue')\n",
    "plt.xlabel('Godzina publikacji')\n",
    "plt.ylabel('Liczba ogłoszeń')\n",
    "plt.title('Liczba ogłoszeń według godzin publikacji')\n",
    "plt.xticks(range(24))  \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obserwacje:\n",
    "* ##### Dane historyczne zamieszczane były w godzinach pracy miedzy 7 a 16.\n",
    "* ##### Ta obserwacja prowadzi nas do pytania, czy oferty są sprawdzane przez administratorów/moderatorów i dodawane w ich godzinach pracy?\n",
    "* ##### W godzinach wieczornych między 17-6 rano widzimy minimalną aktywność publikacji ofert, co może nam sugerować dodawanie ofert np. zagranicznych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "### 6. Analiza wymaganych umiejętności oraz sposób zatrudnienia.\n",
    "<br><br>\n",
    "\n",
    "#### 1. Umiejętności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skill_df = df[['title', 'skills']]\n",
    "skill_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funkcja do wyodrębnienia nazw umiejętności\n",
    "def extract_skill_names(skills_str):\n",
    "    try:\n",
    "        skills = ast.literal_eval(skills_str)\n",
    "        return [skill['name'] for skill in skills if 'name' in skill]\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Wyodrębnienie i zliczenie umiejętności\n",
    "all_skills = skill_df['skills'].apply(extract_skill_names)\n",
    "all_skills_flat = [skill for sublist in all_skills for skill in sublist]\n",
    "\n",
    "# Zliczanie i wybieranie top 30 umiejętności\n",
    "skill_counts = Counter(all_skills_flat)\n",
    "top_skills = skill_counts.most_common(30)\n",
    "\n",
    "# Przygotowanie danych do wykresu\n",
    "names, counts = zip(*top_skills)\n",
    "\n",
    "# Tworzenie wykresu popularności umiejętności\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(names, counts, color='skyblue')\n",
    "plt.title('Top 30 najczęściej występujących umiejętności')\n",
    "plt.xlabel('Umiejętności')\n",
    "plt.ylabel('Liczba wystąpień')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wyliczenie ilości unikalnych umiejętności\n",
    "unique_skills_count = len(skill_counts)\n",
    "\n",
    "# Całkowita liczba wystąpień wszystkich umiejętności\n",
    "total_occurrences = sum(skill_counts.values())\n",
    "\n",
    "# Przygotowanie tekstu dla top 30 umiejętności\n",
    "top_30_text = '\\n'.join([\n",
    "    f\"- {skill}: {count} ({count / total_occurrences:.2%})\"\n",
    "    for skill, count in top_skills\n",
    "])\n",
    "\n",
    "# Tworzenie markdownu z podsumowaniem\n",
    "mark6 = f\"\"\"\n",
    "### Obserwacje:\n",
    "#### 1. Ilość unikalnych umiejętności w danych: {unique_skills_count}\n",
    "#### 2. Trzydzieści najczęściej wymienianych umiejętności w ofertach pracy:\\n{top_30_text}\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(mark6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sposób zatrudnienia / wspólpracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funkcja do wyodrębnienia typów współpracy\n",
    "def extract_collaboration_types(types_str):\n",
    "    try:\n",
    "        types = ast.literal_eval(types_str)\n",
    "        return [item['type'] for item in types if 'type' in item]\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Wyodrębnienie i zliczenie typów współpracy\n",
    "all_collaboration_types = df['employment_types'].apply(extract_collaboration_types)\n",
    "all_collaboration_flat = [t for sublist in all_collaboration_types for t in sublist]\n",
    "\n",
    "# Liczenie wystąpień każdego typu współpracy\n",
    "collaboration_counts = Counter(all_collaboration_flat)\n",
    "collaboration_counts = pd.Series(collaboration_counts).sort_values(ascending=False)\n",
    "\n",
    "# Obliczanie procentowych wartości\n",
    "total_counts = collaboration_counts.sum()\n",
    "collaboration_percents = (collaboration_counts / total_counts * 100).round(1)\n",
    "\n",
    "# Przygotowanie tekstu do podsumowania\n",
    "collaboration_text = '\\n'.join(\n",
    "    [f\"- {method}: {count} ({percent}%)\" for method, count, percent in zip(collaboration_counts.index, collaboration_counts.values, collaboration_percents.values)]\n",
    ")\n",
    "\n",
    "# Wyświetlanie wykresu kołowego\n",
    "sizes = collaboration_counts.values\n",
    "labels = collaboration_counts.index\n",
    "colors = plt.cm.tab20.colors[:len(labels)]  # Wybieranie kolorów z palety\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # Ustalenie rozmiaru wykresu\n",
    "\n",
    "wedges, texts, autotexts = plt.pie(\n",
    "    sizes, \n",
    "    autopct='%1.1f%%', \n",
    "    startangle=90, \n",
    "    colors=colors,\n",
    "    textprops=dict(color=\"white\")  # Tekst wartości procentowej na białym tle\n",
    ")\n",
    "\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontsize(10)\n",
    "    autotext.set_color('white')\n",
    "\n",
    "plt.title('Typy Współpracy')\n",
    "plt.axis('equal')  # Zapewnienie, że koło jest okrągłe\n",
    "\n",
    "plt.legend(wedges, labels, title=\"Typy współpracy\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tworzenie markdownowych wniosków do wyświetlenia\n",
    "mark7= f\"\"\"\n",
    "### Obserwacje dotyczące sposobów współpracy:\n",
    "#### Najczęściej wymieniane sposoby współpracy:\\n{collaboration_text}.\n",
    "\"\"\"\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "display(Markdown(mark7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Analiza wynagrodzeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funkcja do wyodrębnienia danych o wynagrodzeniach\n",
    "def extract_salary_info(types_str):\n",
    "    try:\n",
    "        types = ast.literal_eval(types_str)\n",
    "        salary_data = []\n",
    "        for item in types:\n",
    "            salary = item.get('salary')\n",
    "            if salary:\n",
    "                salary_from = salary.get('from')\n",
    "                salary_to = salary.get('to')\n",
    "                salary_currency = salary.get('currency')\n",
    "                if salary_from is not None and salary_to is not None:\n",
    "                    salary_data.append({\n",
    "                        'type': item.get('type'),\n",
    "                        'salary': int(salary_from),\n",
    "                        'range': 'from',\n",
    "                        'currency': salary_currency\n",
    "                    })\n",
    "                    salary_data.append({\n",
    "                        'type': item.get('type'),\n",
    "                        'salary': int(salary_to),\n",
    "                        'range': 'to',\n",
    "                        'currency': salary_currency\n",
    "                    })\n",
    "        return salary_data\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Rozpakowywanie danych o wynagrodzeniach.\n",
    "salary_info_list = df['employment_types'].apply(extract_salary_info)\n",
    "\n",
    "# Konwersja do płaskiej listy słowników\n",
    "salary_info_flat = [item for sublist in salary_info_list for item in sublist]\n",
    "\n",
    "# Konwersja do DataFrame\n",
    "salary_df = pd.DataFrame(salary_info_flat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definicje kursów wymiany do PLN\n",
    "exchange_rates = {\n",
    "    'usd': 3.97,\n",
    "    'eur': 4.16,\n",
    "    'gbp': 4.99,\n",
    "    'chf': 4.40\n",
    "}\n",
    "\n",
    "def convert_to_pln(row):\n",
    "    currency = row['currency']\n",
    "\n",
    "    if currency in exchange_rates:\n",
    "        rate = exchange_rates[currency]\n",
    "        # Konwersja do float, przeliczenie, zaokrąglenie i konwersja do int\n",
    "        row['salary'] = int(round(float(row['salary']) * rate))\n",
    "        row['currency'] = 'pln'\n",
    "    else:\n",
    "        # Gdy waluta już jest PLN, zaokrąglamy i konwertujemy do int\n",
    "        row['salary'] = int(round(float(row['salary'])))\n",
    "    return row\n",
    "\n",
    "# Iteracyjne stosowanie konwersji dla każdej linii tabeli salary_df\n",
    "salary_df = salary_df.apply(convert_to_pln, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warunkowe dzielenie/mnożenie dla wynagrodzenia\n",
    "salary_df['salary'] = salary_df['salary'].apply(lambda x: x / 12 if x > 80000 else x)\n",
    "salary_df['salary'] = salary_df['salary'].apply(lambda x: x * 160 if x < 500 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df.plot(kind='scatter', \n",
    "               x='salary',\n",
    "               y='type',\n",
    "               )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie wykresu boxplot dla wynagrodzeń\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='type', y='salary', hue='range', data=salary_df, palette='pastel', width=0.4)\n",
    "plt.title('Średnie wynagrodzeia dla typów współpracy')\n",
    "plt.xlabel('Typ współpracy')\n",
    "plt.ylabel('Wynagrodzenie (PLN)')\n",
    "plt.yticks(ticks=range(0, int(salary_df['salary'].max()) + 5000, 5000))\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(salary_df, \n",
    "            vars=['type', 'salary', 'currency'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generowanie tekstu markdown\n",
    "markdown_text = f\"\"\"\n",
    "Obserwacje wynagrodzeń we wszystkich typach współpracy:\n",
    "\n",
    "1. Po wstępnych obserwacjach wynagrodzeń w ofertach pracy znaleziono wynagrodznia w obcych walutach.\n",
    "   - wszystkie waluty zagraniczne przekonwertowane na pln dla lepszego zrozumienia danych.\n",
    "2. Obserwacje minimalnego i maksymalnego wynagrodzenia - dokonano naprawy wartości w danych.\n",
    "   - przytuszczalnie najmniejsze wynagrodzenia odnosiły się do stawek dziennych przez co zostały podniesione do wartości miesięcznej.\n",
    "   - wartości max wynagrodzeń zostały przypuszczalnie zinterpretowane na wynagrodzeń rocznych i zostały poprawione na wynagrodzenia miesięczne.\n",
    "3. Obeserwacje po naprawie danych pokazują przedziały płacowe na bardzo zróżnicowanym poziomie.\n",
    "   W typach współpracy 'b2b' oraz 'permanent' znacząca ilość wartości odstających przekraczających maxymalne średnie wynagrodzenie.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(markdown_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analiza trendów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtracja danych według zakresów dat\n",
    "df_22_01_09 = df[(df['published_at'] >= '2022-01-01') & (df['published_at'] <= '2022-09-30')]\n",
    "df_23_01_09 = df[(df['published_at'] >= '2023-01-01') & (df['published_at'] <= '2023-09-30')]\n",
    "df_21_10_12 = df[(df['published_at'] >= '2021-10-01') & (df['published_at'] <= '2021-12-31')]\n",
    "df_22_10_12 = df[(df['published_at'] >= '2022-10-01') & (df['published_at'] <= '2022-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_21_10_12 = len(df_21_10_12)\n",
    "count_22_10_12 = len(df_22_10_12)\n",
    "count_22_01_09 = len(df_22_01_09)\n",
    "count_23_01_09 = len(df_23_01_09)\n",
    "\n",
    "percent_change_21_22_q4 = ((count_22_10_12 - count_21_10_12) / count_21_10_12 * 100) if count_21_10_12 != 0 else 0\n",
    "percent_change_22_23_q1_q3 = ((count_23_01_09 - count_22_01_09) / count_22_01_09 * 100) if count_22_01_09 != 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mar = f\"\"\"\n",
    "<h2>1) Analiza archiwalnych ofert pracy:</h2> \n",
    "\n",
    "<div style='font-size: 20px'>\n",
    "\n",
    "* W okresie od Października do Grudnia 2021 roku opublikowano: **{count_21_10_12}** ofert pracy.\n",
    "* W okresie od Października do Grudnia 2022 roku opublikowano: **{count_22_10_12}** ofert pracy.\n",
    "* Porównując dane z roku 2022 a z 2021 widać wzrost publikacji ogłoszeń aż o: **{percent_change_21_22_q4:.2f}%**,\\n\n",
    "    przez co można stwierdzić rozwój branży IT i zapotrzebowanie na nowych specjalistów.\n",
    "<br><br>\n",
    "\n",
    "* W okresie od Stycznia do Września 2022 roku opublikowano: **{count_22_01_09}** ofert pracy.\n",
    "* W okresie od Stycznia do Września 2023 roku opublikowano: **{count_23_01_09}** ofert pracy.\n",
    "* Co stanowi: **{percent_change_22_23_q1_q3:.2f}%** wzrostu ofert pracy w danych okresach,\\n \n",
    "    przez co można stwierdzić że zapotrzebowanie na wykwalifikowanych pracowników z roku na rok wzrasta.\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(mar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "ax1 = df_22_01_09['title'].value_counts() \\\n",
    "    .head(5) \\\n",
    "    .plot(ax=axes[0], \n",
    "          kind='bar', \n",
    "          title='Top 5 ofert pracy w okresie 01-09.2022')\n",
    "ax1.set_xlabel('Popularne zawody')\n",
    "ax1.set_ylabel('Ilości')\n",
    "\n",
    "ax2 = df_23_01_09['title'].value_counts() \\\n",
    "    .head(5) \\\n",
    "    .plot(ax=axes[1], \n",
    "          kind='bar', \n",
    "          title='Top 5 ofert pracy w okresie 01-09.2023')\n",
    "ax2.set_xlabel('Popularne zawody')\n",
    "ax2.set_ylabel('Ilości')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "ax1 = df_21_10_12['title'].value_counts() \\\n",
    "    .head(5) \\\n",
    "    .plot(ax=axes[0], \n",
    "          kind='bar', \n",
    "          title='Top 5 ofert pracy w okresie 10-12.2021')\n",
    "ax1.set_xlabel('Popularne zawody')\n",
    "ax1.set_ylabel('Ilości')\n",
    "\n",
    "ax2 = df_22_10_12['title'].value_counts() \\\n",
    "    .head(5) \\\n",
    "    .plot(ax=axes[1],\n",
    "          kind='bar', \n",
    "          title='Top 5 ofert pracy w okresie 10-12.2022')\n",
    "ax2.set_xlabel('Popularne zawody')\n",
    "ax2.set_ylabel('Ilości')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obserwacje wstępne:\n",
    "#### Porównując stanowiska pracy z ostatnich lat w danych okresach czasu swierdzono że:\n",
    "####   * Największe zapotrzebowanie było na stanowisko: **Java Developer**, **DevOps Enginner** oraz **PHP Developer**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explvl1 = df_21_10_12['experience_level'].value_counts()\n",
    "total_explvl1 = explvl1.sum()\n",
    "expeLvl1_counts = '\\n'.join([f\"- {explvl1}: {count} ({(count / total_explvl1 * 100):.2f}%)\" for explvl1, count in explvl1.items()])\n",
    "explvl1_labels = explvl1.index\n",
    "explvl1_sizes = explvl1.values\n",
    "\n",
    "explvl2 = df_22_10_12['experience_level'].value_counts()\n",
    "total_explvl2 = explvl2.sum()\n",
    "expeLvl2_counts = '\\n'.join([f\"- {explvl2}: {count} ({(count / total_explvl2 * 100):.2f}%)\" for explvl2, count in explvl2.items()])\n",
    "explvl2_labels = explvl2.index\n",
    "explvl2_sizes = explvl2.values\n",
    "\n",
    "explvl3 = df_22_01_09['experience_level'].value_counts()\n",
    "total_explvl3 = explvl3.sum()\n",
    "expeLvl3_counts = '\\n'.join([f\"- {explvl3}: {count} ({(count / total_explvl3 * 100):.2f}%)\" for explvl3, count in explvl3.items()])\n",
    "explvl3_labels = explvl3.index\n",
    "explvl3_sizes = explvl3.values\n",
    "\n",
    "explvl4 = df_23_01_09['experience_level'].value_counts()\n",
    "total_explvl4 = explvl3.sum()\n",
    "expeLvl4_counts = '\\n'.join([f\"- {explvl4}: {count} ({(count / total_explvl4 * 100):.2f}%)\" for explvl4, count in explvl4.items()])\n",
    "explvl4_labels = explvl4.index\n",
    "explvl4_sizes = explvl4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie wykresów kołowych\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 6))\n",
    "\n",
    "axes[0].pie(explvl1_sizes, labels=explvl1_labels, autopct='%1.1f%%', colors=plt.cm.Accent.colors)\n",
    "axes[0].set_title('Poziom doświadczenia *10-12.2021*')\n",
    "\n",
    "axes[1].pie(explvl2_sizes, labels=explvl2_labels, autopct='%1.1f%%', colors=plt.cm.Accent.colors)\n",
    "axes[1].set_title('Poziom doświadczenia *10-12.2022*')\n",
    "\n",
    "axes[2].pie(explvl3_sizes, labels=explvl3_labels, autopct='%1.1f%%', colors=plt.cm.Accent.colors)\n",
    "axes[2].set_title('Poziom doświadczenia *01-09.2022*')\n",
    "\n",
    "axes[3].pie(explvl4_sizes, labels=explvl4_labels, autopct='%1.1f%%', colors=plt.cm.Accent.colors)\n",
    "axes[3].set_title('Poziom doświadczenia *01-09.2023*')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Analiza archiwalnych ofert pracy z podziałem na poziomy doświadczenia: \n",
    "\n",
    "* #### Z danych archiwalnych wynika że coraz więcej firm wymaga doświadczenia na poziomie *Senior*. \n",
    "* #### W danych jest ponad połowa ofert pracy z wymaganym doświadczeniem na poziomie *Mid* .\n",
    "* #### Niepokojącym trendem spadkowym możemy określić znaczne zmniejszenie zapotrzebowania na osoby z doświadczeniem na poziomie *Junior*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "## Podsumowanie Analizy Danych\n",
    "\n",
    "\n",
    "### 1. Świadomość Danych\n",
    "- #### Źródła: Archiwalne dane ofert pracy z JostJoinIT \n",
    "- #### Wielkość:\n",
    "  - #### Rekordy: 2096717\n",
    "  - #### Kolumny: 15\n",
    "\n",
    "### 2. Podstawowe Statystyki\n",
    "- #### Typy danych: bool, float, int, object.\n",
    "\n",
    "### 3. Jakość Danych\n",
    "- #### Brakujące wartości: Kolumny tekstowe(object) nie posiadają bakujących wartości,\n",
    "  #### w kolumnach z płacami wystepują brakujące wartości.\n",
    "- #### Zidentyfikowano błedy w kolumnach z wynagrodzeniami, ceny podawane w różnych walutach,\n",
    "  #### prawdopodobnie w stawkach dniowych jak i rocznych zostały odpowiednio przygotowane do analizy.\n",
    "- #### Duplikaty: Ponad połowa danych była duplikatami które zostały usunięte przed analizą.\n",
    "\n",
    "### 4. Podsumowania i Wnioski\n",
    "- #### Główne wnioski:\n",
    "  - #### Dane poddane analizie zawierają : 33818 stanowisk pracy z 7676 firm.\n",
    "    - #### Trzy najczęściej wystepujące stanowiska:\n",
    "      - #### Java Developer\n",
    "      - #### DevOps Enginer\n",
    "      - #### PHP Developer\n",
    "  - #### Z danych wynika że prawie wszystkie oferty pracy były zamieszczane w godzinach pracy: 7 - 16,\n",
    "    #### reszta ofert była opublikowana w godzinach nocnych: 17 - 6, co może sugerować dodawanie ofert np. zagranicznych.\n",
    "  - #### Dane przedstawiają trzy sposoby wykonywania pracy:\n",
    "    - #### Praca zdalna: 74.93% \n",
    "    - #### Praca hybrydowa: 22.38%\n",
    "    - #### Praca biurowa: 2.69%\n",
    "      - #### Biorąc pod uwagę okres który obejmuje wszystkie ogłoszenia można stwierdzić że najmniejsze zainteresowanie pracownikami biurowymi było spowodowane przez COVID-19.\n",
    "  - #### Najwiecej ofert pracy jest w:\n",
    "    - #### Warszawa 20.22%\n",
    "    - #### Wrocław 11.52%\n",
    "    - #### Kraków 11.44%\n",
    "  - #### Aż 74.92% ofert pracy umożliwia rekrutacje zdalną, a 35.26% z ofert umożliwia aplikowanie obcokrajowcom z Ukrainy.\n",
    "  - #### Stwierdzono wzrost ilości ofert pracy, analizując dane z lat 2022-2023.\n",
    "  - #### Stanowiska z wymaganym doświadczeniem na poziomie *Mid* cieszą się największą popularnościa bo zajmują ponad 50% dostepnych ofert.\n",
    "  - #### Przybywa ofert pracy z doświadczeniem na poziomie *Senior*.\n",
    "  - #### Bardzo niepokojącym odkryciem jest że ilość ofert pracy z początkującym doświadczeniem na poziomie *Junior*, \n",
    "    #### których w zbiorze danych jest zaledwie 6.3%. Po wykonaniu głębszej analizy zauważono spadek tych stanowisk o około 40%. \n",
    "  - #### Przedziały płacowe sa na bardzo zróżnicowanym posiomie.\n",
    "    - #### W typach współpracy b2b oraz permanent znacząca ilość wartości odstających przekracza maksymalne średnie wynagrodzenie.\n",
    "\n",
    "- ### Następne kroki: \n",
    "  - #### Zaleca się wykonanie porównania archiwalnych danych z nowymi w zakresie spadkowego trendu ofert pracy na rynku *Juniorskim*. \n",
    "  - #### Zaleca się sprawdzenie trendów dla poziomów doświadczeń: *Senior* oraz *Mid*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook archive_eda_jjit.ipynb to html\n",
      "[NbConvertApp] Writing 298611 bytes to archive_eda_jjit.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert archive_eda_jjit.ipynb --to html --no-input --no-prompt --output archive_eda_jjit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart_justjoinit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
